{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain and Retriever using Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get environment variables\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Ingestion / Loading\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader('file.pdf')\n",
    "pdf_document = loader.load()\n",
    "pdf_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Transformation / Data Splitting\n",
    "from langchain.text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_to_chunks = RecursiveCharacterTextSplitter(chunck_size=1000, chunk_overlap=20)\n",
    "chunks = text_to_chunks.split_documents(pdf_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Vector Embedding and Vector Store\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstore import FAISS\n",
    "\n",
    "vector_db = FAISS.from_documents(chunks, OllamaEmbeddings())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flow of the pipeline architecture:\n",
    "1. define retriever as an interface to vector_db using 'as_retriever()'\n",
    "2. define prompt\n",
    "3. define llm model\n",
    "4. define document_chain by combining prompt and llm model using 'create_stuff_documents_chain'\n",
    "5. define retriver_chain by combining retriver and document_chain using 'create_retrieval_chain'\n",
    "6. define output by invoking user_query to retriever_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define retriever\n",
    "retriever = vector_db.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define prompt\n",
    "## -- context is nothing but the documents in the vector db\n",
    "## -- input is nothing but user query\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "                                          Answer the question based only on the following context:\n",
    "                                          {context}\n",
    "                                          Question: {input}\n",
    "                                          \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define LLM\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm = Ollama(model=\"llama2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain Expression Language (LCEL) is used to construct chains. There are many chain constructors available on https://python.langchain.com/v0.1/docs/modules/chains/ but we will use the \"create_stuff_documents_chain\" in this application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langchains's \"create_stuff_document_chain\" takes a list of documents and formats them all into a prompt, then passes that prompt to an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define document_chain = prompt + llm\n",
    "from langchain_chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "document_chain = create_stuff_documents_chain(prompt, llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define retriever_chain = retriever + document_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "retriever_chain = create_retrieval_chain(document_chain, retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define output\n",
    "output = retriever_chain.invoke({\"input\":\"<enter your input>\"})\n",
    "output['answer']"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
